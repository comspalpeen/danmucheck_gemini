# gift_deduplicator.py
import asyncio
import time
import logging
from collections import OrderedDict
from redis_client import get_redis  # ä½¿ç”¨å…¨å±€ Redis å®¢æˆ·ç«¯

logger = logging.getLogger("GiftDeduplicator")

class AsyncGiftDeduplicator:
    # ã€ä¿®æ”¹ã€‘å¢åŠ  max_buffer_size å‚æ•°ï¼Œé»˜è®¤ 10000 æ¡
    def __init__(self, db_handler, timeout_seconds=10, max_buffer_size=10000):
        """
        ç¤¼ç‰©å»é‡å¤„ç†å™¨
        :param db_handler: æ•°æ®åº“å¤„ç†å™¨
        :param timeout_seconds: å¤§ç¤¼ç‰©ç¼“å†²è¶…æ—¶æ—¶é—´
        :param max_buffer_size: ã€æ–°å¢ã€‘ç¼“å†²åŒºæœ€å¤§å®¹é‡
        """
        self.db = db_handler
        self.timeout = timeout_seconds
        self.max_buffer_size = max_buffer_size  # ã€æ–°å¢ã€‘ä¿å­˜ä¸Šé™é…ç½®
        
        # --- æ ¸å¿ƒç¼“å†²åŒº (Strategy C) ---
        # ã€ä¿®æ”¹ã€‘å¿…é¡»æ˜¾å¼ä½¿ç”¨ OrderedDict ä»¥æ”¯æŒ FIFO æ·˜æ±°
        self.buffer = OrderedDict()
        
        # --- L1 æœ¬åœ°å»é‡ç¼“å­˜ ---
        self.local_history = OrderedDict()
        self.LOCAL_HISTORY_SIZE = 1000 
        
        # é’»çŸ³ç¤¼ç‰©ä»·æ ¼ä¿®æ­£é…ç½® (ä¿æŒä¸å˜)
        self.DIAMOND_OVERRIDES = { 
            "é’»çŸ³ç«ç®­": 12001, "é’»çŸ³å˜‰å¹´å": 36000, "é’»çŸ³å…”å…”": 360, "é’»çŸ³é£è‰‡": 23333,
            "é’»çŸ³ç§˜å¢ƒ": 16000, "é’»çŸ³æ¸¸è½®": 7200, "é’»çŸ³é£æœº": 3600, "é’»çŸ³è·‘è½¦": 1500, "é’»çŸ³çƒ­æ°”çƒ": 620, "é’»çŸ³é‚®è½®": 7200
        }

        self.lock = asyncio.Lock()
        self.running = False
        self.cleaner_task = None

    def start(self):
        self.running = True
        self.cleaner_task = asyncio.create_task(self._cleanup_loop())
        logger.info(f"âœ… [Async] ç¤¼ç‰©å¤„ç†å™¨å¯åŠ¨ (BufferSize: {self.max_buffer_size})")

    def _get_unique_key(self, data):
        uid = data.get('user_id', 'unknown')
        gid = data.get('gift_id', 'unknown')
        group_id = data.get('group_id', '0')
        return f"{uid}_{gid}_{group_id}"

    async def _is_duplicate(self, trace_id, combo, repeat_end):
        """
        æ··åˆå»é‡é€»è¾‘ï¼šæœ¬åœ°ç¼“å­˜ -> Redis
        """
        fingerprint = f"{trace_id}_{combo}_{repeat_end}"
        
        # 1. L1 æœ¬åœ°å¿«é€Ÿæ£€æŸ¥ (å†…å­˜çº§é€Ÿåº¦)
        if fingerprint in self.local_history:
            return True
            
        # 2. L2 Redis æƒå¨æ£€æŸ¥
        # key æ ¼å¼: gift_dedup:{trace_id}_{combo}_{repeat_end}
        redis_key = f"dedup:gift:{fingerprint}"
        redis_client = get_redis()  # è·å–å…¨å±€ Redis å®¢æˆ·ç«¯
        
        try:
            # SET key value NX EX 600
            # NX: åªæœ‰é”®ä¸å­˜åœ¨æ—¶æ‰è®¾ç½® (åŸå­æ“ä½œ)
            # EX: 10åˆ†é’Ÿåè¿‡æœŸ (è‡ªåŠ¨é‡Šæ”¾ Redis å†…å­˜)
            is_new = await redis_client.set(redis_key, 1, nx=True, ex=600)
            
            if not is_new:
                # Redis è¿”å› None/Falseï¼Œè¯´æ˜ Key å·²å­˜åœ¨ -> æ˜¯é‡å¤åŒ…
                # é¡ºä¾¿å†™å…¥æœ¬åœ°ç¼“å­˜ï¼Œæ‹¦æˆªåç»­çš„å¿«é€Ÿé‡è¯•
                self.local_history[fingerprint] = True
                if len(self.local_history) > self.LOCAL_HISTORY_SIZE:
                    self.local_history.popitem(last=False)
                return True
                
            # æ˜¯æ–°åŒ…
            return False
            
        except Exception as e:
            logger.error(f"âš ï¸ Redis è¿æ¥å¼‚å¸¸ï¼Œé™çº§é€šè¿‡: {e}")
            return False # å¼‚å¸¸æ—¶ä¸ºäº†ä¸ä¸¢æ•°æ®ï¼Œé»˜è®¤ä¸è¿‡æ»¤

    async def process_gift(self, gift_data):
        trace_id = gift_data.get('trace_id', '')
        repeat_end = gift_data.get('repeat_end', 0)
        combo = gift_data.get('combo_count', 1)
        gift_name = gift_data.get('gift_name', '')
        gift_id = str(gift_data.get('gift_id', ''))
        room_id = gift_data.get('room_id')
        
        diamond_count = gift_data.get('diamond_count', 0)
        group_count = gift_data.get('group_count', 1)

        # --- 1. ç‰¹æ®Šç¤¼ç‰©ï¼šç²‰ä¸å›¢ç¯ç‰Œ (ä¸è¿‡æ»¤ï¼Œç›´æ¥ç»Ÿè®¡) ---
        if gift_id == "685" or "ç¯ç‰Œ" in gift_name:
            if self.db:
                # ã€ä¿®å¤ã€‘æ„é€ å¢é‡æ•°æ®ï¼ŒåŒæ—¶å¢åŠ ç¯ç‰Œæ•°å’Œé’»çŸ³æ•°
                inc_data = {"fans_ticket_count": 1}
                
                # å¦‚æœç¯ç‰Œæœ‰ä»·å€¼ï¼ˆé€šå¸¸æ˜¯1é’»ï¼‰ï¼Œä¹ŸåŠ ä¸Š
                if diamond_count > 0:
                    inc_data["total_diamond_count"] = diamond_count
                
                await self.db.increment_room_stats(room_id, inc_data)
            return  # ç»§ç»­ä¿æŒ returnï¼Œä¸å­˜å…¥ live_gifts é›†åˆ

        # --- 2. Redis å»é‡æ£€æŸ¥ ---
        # å¦‚æœ trace_id ä¸ºç©ºï¼Œæ— æ³•å»é‡ï¼Œåªèƒ½æ”¾è¡Œ
        if trace_id and await self._is_duplicate(trace_id, combo, repeat_end):
            return 

        # --- 3. ä»·æ ¼ä¿®æ­£é€»è¾‘ ---
        if "é’»çŸ³" in gift_name and gift_name in self.DIAMOND_OVERRIDES:
            corrected_price = self.DIAMOND_OVERRIDES[gift_name]
            diamond_count = corrected_price
            gift_data['diamond_count'] = corrected_price
        elif gift_name == "è·‘è½¦":
            icon_url = gift_data.get('gift_icon_url', '')
            if "diamond_paoche_icon.png" in icon_url:
                corrected_price = 1500
                diamond_count = corrected_price     # æ›´æ–°å±€éƒ¨å˜é‡ï¼Œç¡®ä¿åç»­ç­–ç•¥B/Cç”Ÿæ•ˆ
                gift_data['diamond_count'] = corrected_price # æ›´æ–°å†™å…¥DBçš„æ•°æ®
        # --- ç­–ç•¥B: å°ç¤¼ç‰©ç›´æ¥å†™å…¥ (<60é’») ---
        if diamond_count < 60:
            if repeat_end == 0:
                return 
            else:
                total = diamond_count * group_count * int(combo)
                gift_data['total_diamond_count'] = total
                if int(combo) > 0 and self.db:
                    await self.db.insert_gift(gift_data)
                return

        # --- ç­–ç•¥C: å¤§ç¤¼ç‰©ç¼“å†²èšåˆ (>=60é’») ---
        # è¿™éƒ¨åˆ†é€»è¾‘ä¿æŒåœ¨å†…å­˜ä¸­ï¼Œå› ä¸ºæ˜¯é«˜é¢‘çš„ update æ“ä½œï¼Œ
        # å¦‚æœæŠŠèšåˆé€»è¾‘ä¹Ÿæ”¾åˆ° Redisï¼Œç½‘ç»œ RTT ä¼šæˆä¸ºç“¶é¢ˆã€‚
        key = self._get_unique_key(gift_data)
        current_time = time.time()

        async with self.lock:
            # Case 1: Key å·²å­˜åœ¨ï¼Œç›´æ¥æ›´æ–°ï¼ˆä¸å¢åŠ  buffer é•¿åº¦ï¼‰
            if key in self.buffer:
                cached_item = self.buffer[key]
                if int(combo) > cached_item['max_combo']:
                    cached_item['max_combo'] = int(combo)
                    cached_item['combo_count'] = int(combo)
                if group_count > cached_item.get('group_count', 1):
                    cached_item['group_count'] = group_count
                
                cached_item['last_update_time'] = current_time
                # å°†æ›´æ–°è¿‡çš„é¡¹ç›®ç§»åˆ°æœ«å°¾ï¼ˆè¡¨ç¤ºæœ€è¿‘æ´»è·ƒï¼‰ï¼Œæ–¹ä¾¿ LRU/FIFO é€»è¾‘
                self.buffer.move_to_end(key)

                if repeat_end == 1:
                    cached_item['repeat_end'] = 1
                    cached_item['_force_flush'] = True 
            else:
                # ã€æ–°å¢ã€‘ç¼“å†²åŒºæº¢å‡ºä¿æŠ¤ (FIFO æ·˜æ±°)
                if len(self.buffer) >= self.max_buffer_size:
                    # å¼¹å‡ºæœ€æ—©æ’å…¥ï¼ˆæˆ–æœ€ä¹…æœªæ›´æ–°ï¼‰çš„ä¸€ä¸ªå…ƒç´ 
                    evicted_key, evicted_item = self.buffer.popitem(last=False)
                    # ç«‹å³å°†è¯¥å…ƒç´ å†™å…¥ DB
                    await self._flush_single_data_direct(evicted_item)
                    # è®°å½•æ—¥å¿—ï¼ˆå¯é€‰ï¼Œè°ƒè¯•ç”¨ï¼Œç”Ÿäº§ç¯å¢ƒå¯å»æ‰ä»¥å‡å°‘IOï¼‰
                    # logger.warning(f"âš ï¸ Bufferå·²æ»¡({self.max_buffer_size})ï¼Œå¼ºåˆ¶é©±é€: {evicted_key}")

                # æ­£å¸¸æ’å…¥æ–°å…ƒç´ 
                gift_data['last_update_time'] = current_time
                gift_data['max_combo'] = int(combo)
                gift_data['combo_count'] = int(combo)
                gift_data['group_count'] = group_count
                gift_data['diamond_count'] = diamond_count
                self.buffer[key] = gift_data
    async def _flush_item(self, key):
        data_to_write = None
        async with self.lock:
            if key in self.buffer:
                data_to_write = self.buffer.pop(key)

        if data_to_write and self.db:
            # æ¸…ç†è¾…åŠ©å­—æ®µ
            for field in ['last_update_time', 'max_combo', '_force_flush']:
                data_to_write.pop(field, None)
            
            unit_price = data_to_write.get('diamond_count', 0)
            group_count = data_to_write.get('group_count', 1)
            combo_count = data_to_write.get('combo_count', 1)
            
            data_to_write['total_diamond_count'] = unit_price * group_count * combo_count

            if combo_count > 0:
                await self.db.insert_gift(data_to_write)
    async def _flush_single_data_direct(self, data_to_write):
        if not self.db or not data_to_write: return
        try:
            # æ¸…ç†è¾…åŠ©å­—æ®µ
            for field in ['last_update_time', 'max_combo', '_force_flush']:
                data_to_write.pop(field, None)
            
            unit_price = data_to_write.get('diamond_count', 0)
            group_count = data_to_write.get('group_count', 1)
            combo_count = data_to_write.get('combo_count', 1)
            
            data_to_write['total_diamond_count'] = unit_price * group_count * combo_count
            
            if combo_count > 0:
                # è°ƒç”¨ DB çš„ insert_gift (å®ƒä¼šå°†æ•°æ®æ”¾å…¥ Redis Queueï¼Œéå¸¸å¿«)
                await self.db.insert_gift(data_to_write)
        except Exception as e:
            logger.error(f"âŒ å¼ºåˆ¶å†™å…¥å¤±è´¥: {e}")
    async def _cleanup_loop(self):
        while self.running:
            try:
                await asyncio.sleep(1)
            except asyncio.CancelledError:
                break
            
            current_time = time.time()
            keys_to_flush = []

            async with self.lock:
                for key, item in self.buffer.items():
                    last_update = item.get('last_update_time', 0)
                    is_forced = item.get('_force_flush', False)
                    if is_forced or (current_time - last_update > self.timeout):
                        keys_to_flush.append(key)
            
            for key in keys_to_flush:
                await self._flush_item(key)

    async def stop(self):
        self.running = False
        if self.cleaner_task:
            self.cleaner_task.cancel()
            try:
                await self.cleaner_task
            except asyncio.CancelledError:
                pass
        
        # å¼ºåˆ¶åˆ·æ–°ç¼“å†²åŒº
        logger.info(f"ğŸ›‘ [Async] æ­£åœ¨ä¿å­˜å‰©ä½™ {len(self.buffer)} ç»„å¤§ç¤¼ç‰©...")
        async with self.lock:
            keys = list(self.buffer.keys())
        if keys and self.db:
            # å¹¶å‘å†™å…¥åŠ é€Ÿé€€åœº
            await asyncio.gather(*[self._flush_item(key) for key in keys])