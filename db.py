# db.py
import time
import asyncio
import json
from datetime import datetime
import logging
from motor.motor_asyncio import AsyncIOMotorClient
from pymongo.errors import PyMongoError, BulkWriteError, CollectionInvalid
from pymongo import IndexModel, ASCENDING, DESCENDING
from redis_client import get_redis
from datetime import datetime,timedelta
logger = logging.getLogger("DB")


def datetime_serializer(obj):
    """JSON åºåˆ—åŒ–æ—¶å¤„ç† datetime å¯¹è±¡"""
    if isinstance(obj, datetime):
        return obj.isoformat()
    raise TypeError(f"Type {type(obj)} not serializable")


def datetime_deserializer(data: dict) -> dict:
    """å°† ISO æ ¼å¼å­—ç¬¦ä¸²è¿˜åŸä¸º datetime å¯¹è±¡"""
    if 'created_at' in data and isinstance(data['created_at'], str):
        try:
            data['created_at'] = datetime.fromisoformat(data['created_at'])
        except ValueError:
            data['created_at'] = datetime.now()
    return data


class AsyncMongoDBHandler:
    def __init__(self, uri="mongodb://gogogo:chufale@localhost:4396/admin", db_name="douyin_live_data"):
        try:
            # Motor çš„è¿æ¥å»ºç«‹æ˜¯éé˜»å¡çš„
            self.client = AsyncIOMotorClient(uri, serverSelectionTimeoutMS=5000)
            self.db = self.client[db_name]
            
            # Redis ç¼“å†²åŒº Key
            self.REDIS_CHAT_KEY = "buffer:chats"
            self.REDIS_GIFT_KEY = "buffer:gifts"
            
            # é…ç½®
            self.BATCH_SIZE = 500
            self.LAST_WRITE_TIME = time.time()
            self.BUFFER_TIMEOUT = 5  # ç¼©çŸ­å†™å…¥é—´éš”ï¼Œé€‚åº”æ—¶åºæ•°æ®
            
            # å®šä¹‰æ—¶åºé›†åˆåç§°
            self.COL_GIFT = "live_gifts"
            self.COL_CHAT = "live_chats"
            
            logger.info(f"âœ… [Async] MongoDB Client åˆå§‹åŒ–å®Œæˆ: {db_name}")
        except Exception as e:
            logger.error(f"âŒ MongoDB åˆå§‹åŒ–å¤±è´¥: {e}")
            raise e

    async def init_indexes(self):
        """
        åˆå§‹åŒ–ç´¢å¼•åŠ Time Series é›†åˆ
        """
        try:
            existing_cols = await self.db.list_collection_names()

            # --- 1. åˆ›å»ºç¤¼ç‰©æ—¶åºé›†åˆ ---
            if self.COL_GIFT not in existing_cols:
                try:
                    await self.db.create_collection(
                        self.COL_GIFT,
                        timeseries={
                            "timeField": "created_at",   # å¿…é¡»æ˜¯ Date ç±»å‹
                            "metaField": "web_rid",      # ç”¨äºç´¢å¼•å’Œåˆ†æ¡¶çš„å…³é”®å­—æ®µ
                            "granularity": "seconds"     # ç›´æ’­æ•°æ®ç²’åº¦ä¸ºç§’çº§
                        }
                    )
                    logger.info(f"âœ… åˆ›å»ºæ—¶åºé›†åˆ: {self.COL_GIFT}")
                except CollectionInvalid:
                    pass # å¯èƒ½å¹¶å‘åˆ›å»ºå·²å­˜åœ¨

            # --- 2. åˆ›å»ºå¼¹å¹•æ—¶åºé›†åˆ ---
            if self.COL_CHAT not in existing_cols:
                try:
                    await self.db.create_collection(
                        self.COL_CHAT,
                        timeseries={
                            "timeField": "created_at",
                            "metaField": "web_rid",
                            "granularity": "seconds"
                        }
                    )
                    logger.info(f"âœ… åˆ›å»ºæ—¶åºé›†åˆ: {self.COL_CHAT}")
                except CollectionInvalid:
                    pass

            # --- 3. åˆ›å»ºå¸¸è§„ç´¢å¼• ---
            # Authors ç´¢å¼•
            await self.db['authors'].create_index("sec_uid", unique=True)
            
            # Rooms ç´¢å¼•
            await self.db['rooms'].create_index([("room_id", ASCENDING)])
            await self.db['rooms'].create_index([("live_status", ASCENDING)])
            
            # PK å†å²ç´¢å¼•
            await self.db['pk_history'].create_index([("battle_id", ASCENDING), ("room_id", ASCENDING)])
            
            # ä¸ºæ—¶åºé›†åˆè¡¥å……äºŒçº§ç´¢å¼•
            await self.db[self.COL_GIFT].create_index([("gift_name", ASCENDING)])
            await self.db[self.COL_CHAT].create_index([("user_id", ASCENDING)])
            
            await self.db[self.COL_GIFT].create_index([("room_id", ASCENDING), ("total_diamond_count", DESCENDING)])
            await self.db[self.COL_GIFT].create_index([("room_id", ASCENDING), ("gift_name", ASCENDING)])
            await self.db[self.COL_GIFT].create_index([("room_id", ASCENDING), ("user_name", ASCENDING)])

            # å¼¹å¹•ç´¢å¼•
            await self.db[self.COL_CHAT].create_index([("room_id", ASCENDING), ("created_at", DESCENDING)])
            await self.db[self.COL_CHAT].create_index([("room_id", ASCENDING), ("user_name", ASCENDING)])
            await self.db[self.COL_CHAT].create_index([("user_name", ASCENDING)])
            await self.db[self.COL_CHAT].create_index([("sec_uid", ASCENDING)]) # ç”¨äºç²¾å‡†æœID
            
            await self.db['pk_history'].create_index([("room_id", ASCENDING), ("created_at", DESCENDING)])
            
            logger.info("âœ… æ•°æ®åº“é›†åˆä¸ç´¢å¼•æ£€æŸ¥å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ ç´¢å¼•/é›†åˆåˆå§‹åŒ–å¤±è´¥: {e}")

    async def save_room_info(self, data: dict):
        """ä¿å­˜ç›´æ’­é—´åŸºç¡€ä¿¡æ¯ (å¸¸è§„é›†åˆ)"""
        if not data: return
        try:
            update_fields = data.copy()
            
            if 'created_at' in update_fields:
                update_fields.pop('created_at')

            update_fields['updated_at'] = datetime.now()
            insert_fields = {"created_at": datetime.now()}

            if 'start_follower_count' in update_fields:
                insert_fields['start_follower_count'] = update_fields.pop('start_follower_count')
            else:
                insert_fields['start_follower_count'] = 0

            await self.db['rooms'].update_one(
                {"room_id": data['room_id']}, 
                {
                    "$set": update_fields,
                    "$setOnInsert": insert_fields
                },
                upsert=True
            )
        except PyMongoError as e:
            logger.error(f"âŒ [DB] ä¿å­˜ç›´æ’­é—´ä¿¡æ¯å¤±è´¥: {e}")

    async def set_room_ended(self, room_id: str):
        if not room_id: return
        try:
            end_time = datetime.now()
            await self.db['rooms'].update_one(
                {"room_id": room_id},
                {
                    "$set": {
                        "live_status": 4, 
                        "room_status": 4,
                        "end_time": end_time,
                        "updated_at": end_time
                    }
                }
            )
            logger.info(f"ğŸ [DB] ç›´æ’­é—´ {room_id} å·²æ ‡è®°ä¸ºç»“æŸ")
        except PyMongoError as e:
            logger.error(f"âŒ [DB] æ ‡è®°ç»“æŸå¤±è´¥: {e}")

    async def update_room_realtime(self, room_id: str, live_status: int, current_follower_count: int):
        if not room_id: return
        try:
            update_fields = {
                "updated_at": datetime.now(),
                "live_status": live_status, 
                "room_status": live_status, 
            }
            if current_follower_count > 0:
                update_fields["current_follower_count"] = current_follower_count
                room = await self.db['rooms'].find_one({"room_id": room_id}, {"start_follower_count": 1})
                if room:
                    start_count = room.get('start_follower_count', 0)
                    if start_count > 0:
                        update_fields["follower_diff"] = current_follower_count - start_count

            await self.db['rooms'].update_one({"room_id": room_id}, {"$set": update_fields})
        except PyMongoError as e:
            logger.error(f"âŒ [DB] æ›´æ–°å®æ—¶æ•°æ®å¤±è´¥: {e}")

    async def save_author_card(self, data: dict):
        if not data or not data.get('sec_uid'): return
        try:
            data['updated_at'] = datetime.now()
            await self.db['authors'].update_one(
                {"sec_uid": data['sec_uid']}, 
                {"$set": data},
                upsert=True
            )
        except PyMongoError as e:
            logger.error(f"âŒ [DB] ä¿å­˜ä¸»æ’­èµ„æ–™å¤±è´¥: {e}")

    # --------------------------------------------------------------------------
    # é’ˆå¯¹ Time Series ä¼˜åŒ–çš„å†™å…¥é€»è¾‘
    # --------------------------------------------------------------------------

    async def insert_gift(self, data: dict):
        """
        å¼‚æ­¥ä¿å­˜ç¤¼ç‰©ä¿¡æ¯ (Redis ç¼“å†² + æ‰¹é‡å†™å…¥æ—¶åºé›†åˆ)
        """
        if not data: return
        try:
            if isinstance(data.get('created_at'), str):
                try:
                    data['created_at'] = datetime.now() 
                except:
                    data['created_at'] = datetime.now()
            elif not data.get('created_at'):
                data['created_at'] = datetime.now()
            
            redis_client = get_redis()
            json_data = json.dumps(data, default=datetime_serializer)
            await redis_client.rpush(self.REDIS_GIFT_KEY, json_data)
            
            current_time = time.time()
            buffer_size = await redis_client.llen(self.REDIS_GIFT_KEY)
            
            if buffer_size >= self.BATCH_SIZE or (current_time - self.LAST_WRITE_TIME > self.BUFFER_TIMEOUT):
                await self.flush_gift_buffer()

        except Exception as e:
            logger.error(f"âŒ [DB] ç¼“å†²ç¤¼ç‰©å¤±è´¥: {e}")

    async def flush_gift_buffer(self):
        """åˆ·æ–°ç¤¼ç‰©ç¼“å†²åŒº -> live_gifts (TimeSeries) [å®‰å…¨ç‰ˆ]"""
        try:
            redis_client = get_redis()
            BATCH_COUNT = 1000
            
            raw_data_list = await redis_client.lpop(self.REDIS_GIFT_KEY, count=BATCH_COUNT)
            
            if not raw_data_list:
                return

            current_batch = []
            for raw in raw_data_list:
                try:
                    data = json.loads(raw)
                    data = datetime_deserializer(data)
                    current_batch.append(data)
                except: pass
            
            if not current_batch:
                return
            
            try:
                await self.db[self.COL_GIFT].insert_many(current_batch, ordered=False)
                
                room_diamond_sum = {}
                for gift in current_batch:
                    room_id = gift.get('room_id')
                    diamond = gift.get('total_diamond_count', 0)
                    
                    if diamond == 0:
                        d = gift.get('diamond_count', 0)
                        c = gift.get('combo_count', 1)
                        g = gift.get('group_count', 1)
                        diamond = d * c * g
    
                    if room_id and diamond > 0:
                        room_diamond_sum[room_id] = room_diamond_sum.get(room_id, 0) + diamond
                
                for room_id, diamond_inc in room_diamond_sum.items():
                    await self.db['rooms'].update_one(
                        {"room_id": str(room_id)}, 
                        {
                            "$inc": {"total_diamond_count": diamond_inc},
                            "$set": {"updated_at": datetime.now()}
                        },
                        upsert=True
                    )

            except Exception as e:
                logger.error(f"âŒ [DB] æ‰¹é‡å†™å…¥ç¤¼ç‰©å¤±è´¥: {e}")
                if raw_data_list:
                     await redis_client.rpush(self.REDIS_GIFT_KEY, *raw_data_list)

        except Exception as e:
            logger.error(f"âŒ [DB] åˆ·æ–°ç¤¼ç‰©å¼‚å¸¸: {e}")

    async def insert_chat(self, data: dict):
        """
        å¼‚æ­¥ä¿å­˜å¼¹å¹•ä¿¡æ¯ (Redis ç¼“å†² + æ‰¹é‡å†™å…¥æ—¶åºé›†åˆ)
        """
        if not data: return
        try:
            if isinstance(data.get('created_at'), str) or not data.get('created_at'):
                data['created_at'] = datetime.now()

            redis_client = get_redis()
            json_data = json.dumps(data, default=datetime_serializer)
            await redis_client.rpush(self.REDIS_CHAT_KEY, json_data)
            
            current_time = time.time()
            buffer_size = await redis_client.llen(self.REDIS_CHAT_KEY)
            
            if buffer_size >= self.BATCH_SIZE or (current_time - self.LAST_WRITE_TIME > self.BUFFER_TIMEOUT):
                await self.flush_chat_buffer()
        except Exception as e:
            logger.error(f"âŒ [DB] ç¼“å†²å¼¹å¹•å¤±è´¥: {e}")

    async def flush_chat_buffer(self):
        """åˆ·æ–°å¼¹å¹•ç¼“å†²åŒº -> live_chats (TimeSeries)"""
        try:
            redis_client = get_redis()
            buffer_size = await redis_client.llen(self.REDIS_CHAT_KEY)
            if buffer_size == 0:
                return
        except RuntimeError as e:
            logger.warning(f"âš ï¸ [DB] Redis ä¸å¯ç”¨ï¼Œè·³è¿‡å¼¹å¹•ç¼“å†²åˆ·æ–°: {e}")
            return
        except Exception as e:
            logger.error(f"âŒ [DB] æ£€æŸ¥ Redis ç¼“å†²åŒºå¤±è´¥: {e}")
            return
        
        self.LAST_WRITE_TIME = time.time()

        try:
            pipe = redis_client.pipeline()
            pipe.lrange(self.REDIS_CHAT_KEY, 0, -1)
            pipe.delete(self.REDIS_CHAT_KEY)
            results = await pipe.execute()
            
            raw_data_list = results[0]
            if not raw_data_list:
                return
            
            current_batch = []
            for raw in raw_data_list:
                try:
                    data = json.loads(raw)
                    data = datetime_deserializer(data)
                    current_batch.append(data)
                except json.JSONDecodeError as e:
                    logger.error(f"âŒ [DB] JSON è§£æå¤±è´¥: {e}")
            
            if not current_batch:
                return
            
            await self.db[self.COL_CHAT].insert_many(current_batch, ordered=False)
            
            room_chat_count = {}
            for chat in current_batch:
                room_id = chat.get('room_id')
                if room_id:
                    room_chat_count[room_id] = room_chat_count.get(room_id, 0) + 1
            
            for room_id, chat_inc in room_chat_count.items():
                await self.db['rooms'].update_one(
                    {"room_id": room_id},
                    {
                        "$inc": {"total_chat_count": chat_inc},
                        "$set": {"updated_at": datetime.now()}
                    },
                    upsert=True
                )
            
            logger.debug(f"ğŸ“¦ [DB] å·²å†™å…¥ {len(current_batch)} æ¡å¼¹å¹•è®°å½•")
                
        except Exception as e:
            logger.error(f"âŒ [DB] åˆ·æ–°å¼¹å¹•å¼‚å¸¸: {e}")

    async def update_room_stats(self, room_id, stats: dict):
        """æ›´æ–°æˆ¿é—´çŠ¶æ€ (ä»ä¿ç•™ï¼Œå› ä¸ºæ˜¯æ›´æ–° rooms è¡¨)"""
        if not room_id or not stats: return
        try:
            update_fields = {"updated_at": datetime.now()}
            
            if 'user_count' in stats: update_fields['user_count'] = stats['user_count']
            if 'total_user' in stats: update_fields['total_user_count'] = stats['total_user']
            if 'like_count' in stats: update_fields['like_count'] = stats['like_count']
            if 'live_status' in stats: 
                update_fields['live_status'] = stats['live_status']
                update_fields['room_status'] = stats['live_status']
            if 'ranks' in stats: 
                update_fields['ranks'] = stats['ranks']

            pipeline = {"$set": update_fields}
            if 'user_count' in stats:
                pipeline["$max"] = {"max_viewers": stats['user_count']}
                
            await self.db['rooms'].update_one({"room_id": room_id}, pipeline, upsert=True)
        except PyMongoError:
            pass

    async def save_pk_result(self, pk_data: dict):
        if not pk_data: return
        try:
            await self.db['pk_history'].update_one(
                {
                    "battle_id": pk_data['battle_id'],
                    "room_id": pk_data['room_id']
                },
                {"$set": pk_data},
                upsert=True
            )
            logger.info(f"âš”ï¸ [DB] PKæ•°æ®å·²ä¿å­˜: {pk_data['battle_id']}")
        except PyMongoError as e:
            logger.error(f"âŒ [DB] ä¿å­˜PKæ•°æ®å¤±è´¥: {e}")

    async def increment_room_stats(self, room_id: str, inc_data: dict):
        if not room_id or not inc_data: return
        try:
            await self.db['rooms'].update_one(
                {"room_id": room_id},
                {
                    "$inc": inc_data,
                    "$set": {"updated_at": datetime.now()}
                },
                upsert=True
            )
        except Exception as e:
            logger.error(f"âŒ [DB] é€’å¢ç»Ÿè®¡å¤±è´¥: {e}")

    async def close(self):
        logger.info("ğŸ’¾ æ­£åœ¨å°† Redis ç¼“å†²åŒºæ•°æ®å†™å…¥ MongoDB...")
        await self.flush_chat_buffer()
        await self.flush_gift_buffer()
        # ç§»é™¤äº† flush_stat_buffer
        self.client.close()
        logger.info("ğŸ‘‹ MongoDB è¿æ¥å·²å…³é—­")

    async def get_room_live_status(self, room_id: str):
        """
        ã€æ–°å¢ã€‘è·å–æŒ‡å®šæˆ¿é—´çš„å½“å‰æ•°æ®åº“çŠ¶æ€
        ç”¨äº main.py åˆ¤æ–­æ˜¯å¦éœ€è¦é‡å¯å½•åˆ¶
        """
        try:
            res = await self.db['rooms'].find_one(
                {"room_id": room_id}, 
                {"live_status": 1}
            )
            if res:
                return res.get('live_status', 0)
        except Exception:
            pass
        return 0

    async def get_all_cookies(self):
        """è·å–æ‰€æœ‰ Cookie"""
        cookies = []
        async for doc in self.db['settings_cookies'].find({}, {"_id": 0}):
            if doc.get('cookie'):
                cookies.append(doc['cookie'])
        return cookies

    async def add_cookie(self, cookie_str: str):
        """æ·»åŠ ä¸€ä¸ª Cookie"""
        if not cookie_str: return
        await self.db['sys_config'].update_one(
            {"key": "douyin_cookies"},
            {"$addToSet": {"cookies": cookie_str}},
            upsert=True
        )

    async def delete_cookie(self, cookie_str: str):
        """åˆ é™¤å¤±æ•ˆ Cookie"""
        if not cookie_str: return
        await self.db['settings_cookies'].delete_one({"cookie": cookie_str})
        logger.info(f"ğŸ—‘ï¸ [DB] å·²ç§»é™¤å¤±æ•ˆ Cookie: {cookie_str[:20]}...")
    async def clear_zombie_rooms(self, timeout_seconds=180):
        """
        æ¸…ç†åƒµå°¸æˆ¿é—´ï¼š
        å°†çŠ¶æ€ä¸ºç›´æ’­ä¸­(1)ä½†è¶…æ—¶æœªæ›´æ–°çš„æˆ¿é—´æ ‡è®°ä¸ºç»“æŸã€‚
        ä½¿ç”¨ updated_at ä½œä¸ºç»“æŸæ—¶é—´ï¼Œæ›´åŠ ç²¾ç¡®ã€‚
        """
        try:
            # è®¡ç®—è¶…æ—¶é˜ˆå€¼
            threshold_time = datetime.now() - timedelta(seconds=timeout_seconds)
            
            # 1. æŸ¥æ‰¾æ¡ä»¶ï¼šç›´æ’­ä¸­ ä¸” æœ€åæ›´æ–°æ—¶é—´æ—©äºé˜ˆå€¼
            query = {
                "live_status": 1,
                "updated_at": {"$lt": threshold_time}
            }
            
            # 2. æ›´æ–°æ“ä½œ (æ³¨æ„ï¼šè¿™é‡Œæ˜¯ä¸€ä¸ªåˆ—è¡¨ []ï¼Œè¿™æ˜¯ MongoDB 4.2+ çš„èšåˆæ›´æ–°è¯­æ³•)
            # $updated_at å¼•ç”¨çš„æ˜¯æ–‡æ¡£è‡ªèº«çš„å­—æ®µå€¼
            update_pipeline = [
                {
                    "$set": {
                        "live_status": 4,
                        "room_status": 4,
                        "end_time": "$updated_at",     # <--- æ ¸å¿ƒä¿®æ”¹ï¼šä½¿ç”¨è¯¥æ–‡æ¡£æœ€åä¸€æ¬¡æ›´æ–°çš„æ—¶é—´
                        "end_reason": "zombie_cleanup" # æ ‡è®°åŸå› 
                    }
                }
            ]
            
            result = await self.db['rooms'].update_many(query, update_pipeline)
            
            if result.modified_count > 0:
                logger.warning(f"ğŸ§Ÿâ€â™‚ï¸ [DB] æ¸…ç†äº† {result.modified_count} ä¸ªåƒµå°¸ç›´æ’­é—´ (åˆ¤å®šç»“æŸæ—¶é—´ä¸ºæœ€åæ´»è·ƒæ—¶åˆ»)")
                
        except Exception as e:
            logger.error(f"âŒ [DB] æ¸…ç†åƒµå°¸æˆ¿é—´å¤±è´¥: {e}")  
        
        
        